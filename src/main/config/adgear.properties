## Should set:
# secor.kafka.topic_filter
# secor.adgear.source
# secor.s3.path
# secor.s3.bucket
# aws.access.key=
# aws.secret.key=
secor.s3.bucket=adgear-beh
include=local.adgear.properties

################################################################
## Boilerplate
cloud.service=S3
secor.s3.filesystem=s3n

# Zookeeper config.
zookeeper.session.timeout.ms=3000
zookeeper.sync.time.ms=200

# Zookeeper path (chroot) under which secor data will be placed.
secor.zookeeper.path=/

## Impacts how frequently the upload logic is triggered if no messages are delivered.
## 1 minute:
kafka.consumer.timeout.ms=60000

kafka.partition.assignment.strategy=range
kafka.rebalance.max.retries=
kafka.rebalance.backoff.ms=
kafka.socket.receive.buffer.bytes=
kafka.fetch.message.max.bytes=
kafka.fetch.min.bytes=
kafka.fetch.wait.max.ms=
kafka.seed.broker.port=9092
kafka.zookeeper.path=/kafka

secor.generation=1

# Number of consumer threads per Secor process.
secor.consumer.threads=7

# Consumption rate limit enforced at the process level (not a consumer-thread level).
secor.messages.per.second=10000

# Used by the "backup" consumer group only.
secor.offsets.per.partition=1000000

# How long does it take for secor to forget a topic partition. Applies to stats generation only.
secor.topic_partition.forget.seconds=60

partitioner.granularity.hour=true
partitioner.finalizer.delay.seconds=30

secor.local.log.delete.age.hours=-1
qubole.api.token=
hive.table.prefix=
tsdb.hostport=
monitoring.blacklist.topics=
monitoring.prefix=secor

# Secor can export stats to statsd such as consumption lag (in seconds and offsets) per topic partition.
# Leave empty to disable this functionality.
statsd.hostport=statsd.int.adgear.com:8125

# Name of field that contains timestamp for JSON, MessagePack, or Thrift message parser. (1405970352123)
message.timestamp.name=timestamp
message.timestamp.input.pattern=
secor.compression.codec=org.apache.hadoop.io.compress.GzipCodec

# To set a custom file extension set this to a valid file suffix, such as
# '.gz', '.part', etc.
secor.file.extension=

secor.file.reader.writer.factory=com.pinterest.secor.io.impl.TsvFileReaderWriterFactory
secor.max.message.size.bytes=100000
secor.upload.manager.class=com.pinterest.secor.uploader.HadoopS3UploadManager

secor.max.file.size.bytes=104857600

# For hourly ingestion/finalization, set this property to smaller value, e.g. 1800
secor.max.file.age.seconds=900
successful-upload-touch.file=/tmp/secor.upload.touch
kafka.seed.broker.host=localhost
kafka.seed.broker.port=9092
zookeeper.quorum=localhost:2181

secor.kafka.group=secor_partition
secor.message.parser.class=com.pinterest.secor.parser.NoDateStampJsonMessageParser

# Local path where sequence files are stored before they are uploaded to s3.
secor.local.path=/tmp/secor_dev/message_logs/partition

# Port of the Ostrich server.
ostrich.port=9998
